{
    "contents" : "# =====================================================\n# Stat133: Lab 3\n# Author: Gaston Sanchez\n# Description: Reading data tables\n# =====================================================\n\n\n# =====================================================\n# Data: Create your own data set\n# =====================================================\n# Open your text editor and create a small data table\n# Use blank space as field separator: \" \"\n# Save the data as \"states.txt\"\n# For instance:\n#   state initial capital area\n#   \"California\" CA Sacramento 163707\n#   \"New York\" NY Albany 54475\n#   \"Texas\" TX Austin 268601\n#   \"North Carolina\" NC Raleigh NA\n\n# read the data 'states.txt' in R using read.table()\nstates <- read.table(file = \"states.txt\", header = TRUE, sep = \" \")\n\n# inspect states using the following functions:\nstr(states)\nstates\ndim(states)\nsummary(states)\n\n\n\n# =====================================================\n# Data: \"Body Mass of Late Quarternary Mammals\"\n# =====================================================\n# Source: http://www.esapubs.org/archive/ecol/E084/094/default.htm\n# Reference: \n#   Smith, F. A., et al. (2003)\n#   Body mass of late Quaternary mammals.\n#   Ecology 84:3403.\n# URL: http://www.esapubs.org/archive/ecol/E084/094/MOMv3.3.txt\n\n# Go to the URL of the data\n# What's the field delimiter? \"\\t\"\n# Is there a column header? NO\n# What value is used to indicate missing data? -999\n# How would you import the data in file \"MOMv3.3.txt\"? url <- \"MOMv3.3.txt\", df <- read.table(file = url)\n\n# Here's one option to read the data in R\nurl <- \"http://www.esapubs.org/archive/ecol/E084/094/MOMv3.3.txt\"\ndf <- read.table(file = url, header = FALSE, sep = \"\\t\", na.strings = -999)\n\n# Instead of read.table() what other function could you use?\ndf <- read.delim(file = url, na.strings = -999)\n\n# inspect df using the following functions:\nstr(df)\ndim(df)\nnrow(df)\nncol(df)\nhead(df)\ntail(df)\nsummary(df)\n\n\n# Check the metadata at:\n# http://www.esapubs.org/archive/ecol/E084/094/metadata.htm\n# Look for the variable definitions:\n#   Continent\n#   Status\n#   Order\n#   Family\n#   Genus\n#   Species\n#   LogMass\n#   CombinedMass\n#   Reference\n\n# Read the data again but just the first 100 rows\n# Use the argument col.names to provide a vector of column names\ndf_names <- c('continent', 'status', 'order', 'family', 'genus', 'species', 'logmass', 'combmass', 'reference')\n\ndf2 <- read.delim(file = url, na.strings = -999, nrows = 100, col.names = df_names)\n\nstr(df2, vec.len = 1)\nhead(df2)\nsummary(df2)\n\n\n# Remove the column 'reference'\ndf2$reference <- NULL\n\n# create a new variable 'log2mass' (log base 2 of combmass)\ndf2$log2mass <- log(df2$combmass)\n\n\n\n# =====================================================\n# Data: \"Brac 2006 - fish data\"\n# =====================================================\n# Source: http://datadryad.org/handle/10255/dryad.34126\n# Reference: \n#   Sizling et al. (2011)\n#   Between geometry and biology: the problem of universality \n#   of the species-area relationship.\n#   The American Naturalist 178(5): 602-611.\n# URL: http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1\n\n# Go to the URL of the data\n# What's the field delimiter? \"\\t\"\n# Is there a column header? YES\n# Are there any lines to be skipped? YES\n# How would you import the data in file \"Brac 2006 - fish data\"?\n\nfish_url <- \"http://datadryad.org/bitstream/handle/10255/dryad.34127/Brac%202006%20-%20fish%20data.txt?sequence=1\"\nfish <- read.table(fish_url, header = TRUE, sep=\"\\t\", skip = 1)\n\n# inspect df using the following functions:\nstr(fish)\ndim(fish)\nnrow(fish)\nncol(fish)\nhead(fish)\ntail(fish)\nsummary(fish)\n\n\n\n# =====================================================\n# Data: SF Open Data \"Permit Types\"\n# =====================================================\n# Source: https://data.sfgov.org/City-Infrastructure/Permit-Types/6wa6-8527\n# Reference: \n#   SF Open Data\n# URL: https://data.sfgov.org/City-Infrastructure/Permit-Types/6wa6-8527\n\n# Go to the link of the data\n# The data \"Permit Types\" can be downloaded in several ways\n# Click the \"Export\" button in the menu bar to see those options\n# The goal is to read the data in CSV format\npermits_url <- \"https://data.sfgov.org/api/views/6wa6-8527/rows.csv\"\n\n# try to use read.csv() and see what happens\npermits <- read.csv(permits_url)\n\n# the problem has to do with the Secured HTTP url (i.e. \"https://...\")\n# read.csv() cannot handle 'https'\n\n\n# OPTION 1\n# One solution is to download the file to your computer\n# and then use read.csv()\n# Assuming that the downloaded file is in your working directory:\npt <- read.csv(\"Permit_Types.csv\")\n\n\n# OPTION 2\n# Instead of downloading the file, we can read it directly in R\n# One solution is to use the package RCurl\n# (remember to install it first)\nlibrary(RCurl)\n\n# URL of data file\nperms_url <- getURL(permits_url)\n\n# import data in R (through a text connection)\nperms <- read.csv(textConnection(perms_url))\n\nhead(perms)\n\n\n# OPTION 3 (my preferred one)\n# Another solution is to use the package 'readr'\n# (if you don't have it yet, remember to install it first)\nlibrary(readr)\npermits <- read_csv(permits_url)\nhead(permits)\n\n",
    "created" : 1449449205931.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "738367299",
    "id" : "BBFDD7A0",
    "lastKnownWriteTime" : 1442510891,
    "path" : "~/Desktop/stats133/labsolutions/lab03sol.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "type" : "r_source"
}